{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import xgboost as xgb\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "from scipy.optimize import fmin_powell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code below outputs the Quadratic weighted kappa metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_wrapper(yhat, y):  \n",
    "    y = np.array(y)\n",
    "    y = y.astype(int)\n",
    "    yhat = np.array(yhat)\n",
    "    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n",
    "    return quadratic_weighted_kappa(yhat, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the parameters to tune for the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_params():\n",
    "    \n",
    "    params = {}\n",
    "    params[\"objective\"] = \"reg:linear\"     \n",
    "    params[\"eta\"] = 0.05\n",
    "    params[\"min_child_weight\"] = 360\n",
    "    params[\"subsample\"] = 0.85\n",
    "    params[\"colsample_bytree\"] = 0.3\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"max_depth\"] = 7\n",
    "    plst = list(params.items())\n",
    "\n",
    "    return plst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apply_offsets(data, offsets):\n",
    "    for j in range(num_classes):\n",
    "        data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "columns_to_drop = ['Id', 'Response']\n",
    "xgb_num_rounds = 720\n",
    "num_classes = 8\n",
    "missing_indicator = -1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the data using pandas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59381, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Load the data using pandas\")\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79146, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine train and test\n",
    "all_data = train.append(test)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create any new variables    \n",
    "all_data['Product_Info_2_char'] = all_data.Product_Info_2.str[0]\n",
    "all_data['Product_Info_2_num'] = all_data.Product_Info_2.str[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning numerical variables to string variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# factorize categorical variables\n",
    "all_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\n",
    "all_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]\n",
    "all_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]\n",
    "\n",
    "all_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n",
    "\n",
    "med_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\n",
    "all_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminate missing values\n"
     ]
    }
   ],
   "source": [
    "print('Eliminate missing values')    \n",
    "all_data.fillna(missing_indicator, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix the dtype on the label column\n",
    "all_data['Response'] = all_data['Response'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train = all_data[all_data['Response']>0].copy()\n",
    "test = all_data[all_data['Response']<1].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the data to xgb data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "xgtrain = xgb.DMatrix(train.drop(columns_to_drop, axis=1), train['Response'].values, \n",
    "                        missing=missing_indicator)\n",
    "xgtest = xgb.DMatrix(test.drop(columns_to_drop, axis=1), label=test['Response'].values, \n",
    "                        missing=missing_indicator) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code outputs the parameters for xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('max_depth', 7), ('subsample', 0.85), ('objective', 'reg:linear'), ('min_child_weight', 360), ('silent', 1), ('eta', 0.05), ('colsample_bytree', 0.3)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "plst = get_params()\n",
    "print(plst)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = xgb.train(plst, xgtrain, xgb_num_rounds) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the train and test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is: 0.6516583139089522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_preds = model.predict(xgtrain)        \n",
    "print('Train score is:', eval_wrapper(train_preds, train['Response'])) \n",
    "test_preds = model.predict(xgtest)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Offset Train score is: 0.7027723116346819\n"
     ]
    }
   ],
   "source": [
    "offsets=np.array([-1.5,-2.6,-3.6,-1.2,-0.8,-0.1,0.6,3.6])\n",
    "offset_preds = np.vstack((train_preds, train_preds, train['Response'].values))\n",
    "offset_preds = apply_offsets(offset_preds, offsets)\n",
    "print('Offset Train score is:', eval_wrapper(offset_preds[1], train['Response'])) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The code outputs the offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_offset(data, bin_offset, sv, scorer=eval_wrapper):\n",
    "     #data has the format of pred=0, offset_pred=1, labels=2 in the first dim\n",
    "    data[1, data[0].astype(int)==sv] = data[0, data[0].astype(int)==sv] + bin_offset\n",
    "    score = scorer(data[1], data[2])\n",
    "    return score\n",
    "\n",
    "from scipy.optimize import fmin_powell\n",
    "opt_order = [0,1,2,3,4,5,6,7]\n",
    "for j in opt_order:\n",
    "    train_offset = lambda x: -score_offset(offset_preds, x, j) * 100\n",
    "    offsets[j] = fmin_powell(train_offset, offsets[j], disp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply offsets to the  test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data = np.vstack((test_preds, test_preds, test['Response'].values))\n",
    "data = apply_offsets(data, offsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rounding off the predictions to the given risk interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_out = pd.DataFrame({\"Id\": test['Id'].values, \"Response\": final_test_preds})\n",
    "preds_out = preds_out.set_index('Id')\n",
    "preds_out.to_csv('xgbtl_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
